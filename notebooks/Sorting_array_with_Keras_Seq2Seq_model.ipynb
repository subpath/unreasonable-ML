{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3313537c-f291-4792-92cf-004d9a371391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T19:05:17.358325Z",
     "iopub.status.busy": "2022-04-21T19:05:17.357768Z",
     "iopub.status.idle": "2022-04-21T19:05:22.566961Z",
     "shell.execute_reply": "2022-04-21T19:05:22.565915Z",
     "shell.execute_reply.started": "2022-04-21T19:05:17.358275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using example from https://keras.io/examples/nlp/addition_rnn/\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE: int = 50_000\n",
    "DIGITS: int = 3\n",
    "MAX_NUMBER_OF_ELEMENTS: int = 3\n",
    "REVERSE: bool = True\n",
    "\n",
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN: int = MAX_NUMBER_OF_ELEMENTS * DIGITS + 2 * MAX_NUMBER_OF_ELEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e33c7e66-3455-4bcf-9a0b-e6d4b972df20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T19:05:22.578960Z",
     "iopub.status.busy": "2022-04-21T19:05:22.578329Z",
     "iopub.status.idle": "2022-04-21T19:05:22.610878Z",
     "shell.execute_reply": "2022-04-21T19:05:22.594486Z",
     "shell.execute_reply.started": "2022-04-21T19:05:22.578913Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CharacterTable:\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one-hot integer representation\n",
    "    + Decode the one-hot or integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, chars: str):\n",
    "        \"\"\"Initialize character table.\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = {c: i for i, c in enumerate(self.chars)}\n",
    "        self.indices_char = {i: c for i, c in enumerate(self.chars)}\n",
    "\n",
    "    def encode(self, C: str, num_rows: int):\n",
    "        \"\"\"One-hot encode given string C.\n",
    "        # Arguments\n",
    "            C: string, to be encoded.\n",
    "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x: np.array, calc_argmax=True):\n",
    "        \"\"\"Decode the given vector or 2D array to their character output.\n",
    "        # Arguments\n",
    "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
    "                or a vector of character indices (used with `calc_argmax=False`).\n",
    "            calc_argmax: Whether to find the character index with maximum\n",
    "                probability, defaults to `True`.\n",
    "        \"\"\"\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return \"\".join(self.indices_char[x] for x in x)\n",
    "\n",
    "\n",
    "chars = \"0123456789, \"\n",
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bed84d-3e86-4da6-a867-bcc96bc8c182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T20:39:28.657151Z",
     "iopub.status.busy": "2022-04-18T20:39:28.656666Z",
     "iopub.status.idle": "2022-04-18T20:39:28.663814Z",
     "shell.execute_reply": "2022-04-18T20:39:28.662953Z",
     "shell.execute_reply.started": "2022-04-18T20:39:28.657109Z"
    },
    "tags": []
   },
   "source": [
    "## Generate trainig data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bed65ab-adb3-4522-9618-f4eedc16d74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T19:05:22.619675Z",
     "iopub.status.busy": "2022-04-21T19:05:22.617884Z",
     "iopub.status.idle": "2022-04-21T19:06:00.760655Z",
     "shell.execute_reply": "2022-04-21T19:06:00.759094Z",
     "shell.execute_reply.started": "2022-04-21T19:05:22.619600Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total questions: 50000\n"
     ]
    }
   ],
   "source": [
    "def make_random_number() -> int:\n",
    "    return int(\n",
    "        \"\".join(\n",
    "            np.random.choice(list(\"0123456789\"))\n",
    "            for i in range(np.random.randint(1, DIGITS + 1))\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def make_unified_lenght(string: str) -> str:\n",
    "    return string + \" \" * (MAXLEN - len(string))\n",
    "\n",
    "\n",
    "def list_to_string(list_to_convert: List[int]) -> str:\n",
    "    return \", \".join([str(element) for element in list_to_convert])\n",
    "\n",
    "\n",
    "questions: List[str] = []\n",
    "answers: List[str] = []\n",
    "\n",
    "print(\"Generating data...\")\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    unsorted_list = []\n",
    "    for element_idx in range(MAX_NUMBER_OF_ELEMENTS):\n",
    "        unsorted_list.append(make_random_number())\n",
    "    sorted_list = sorted(unsorted_list)\n",
    "    unsorted_list_as_string, sorted_list_as_string = list_to_string(\n",
    "        unsorted_list\n",
    "    ), list_to_string(sorted_list)\n",
    "    query = make_unified_lenght(unsorted_list_as_string)\n",
    "    answer = make_unified_lenght(sorted_list_as_string)\n",
    "    if query not in questions:\n",
    "        questions.append(query)\n",
    "        answers.append(answer)\n",
    "print(\"Total questions:\", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b539cd-bd48-4f55-a6dd-fb377a7a7f38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T19:06:00.765157Z",
     "iopub.status.busy": "2022-04-21T19:06:00.764174Z",
     "iopub.status.idle": "2022-04-21T19:06:00.824349Z",
     "shell.execute_reply": "2022-04-21T19:06:00.811988Z",
     "shell.execute_reply.started": "2022-04-21T19:06:00.765108Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28, 488, 687   ',\n",
       " '0, 90, 546     ',\n",
       " '399, 3, 80     ',\n",
       " '8, 881, 37     ',\n",
       " '46, 791, 7     ',\n",
       " '65, 124, 5     ',\n",
       " '5, 61, 375     ',\n",
       " '0, 4, 82       ',\n",
       " '1, 785, 49     ',\n",
       " '25, 900, 399   ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1d834e-4184-4e52-8136-c4929e25d23d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T19:06:00.836940Z",
     "iopub.status.busy": "2022-04-21T19:06:00.835536Z",
     "iopub.status.idle": "2022-04-21T19:06:00.895554Z",
     "shell.execute_reply": "2022-04-21T19:06:00.889003Z",
     "shell.execute_reply.started": "2022-04-21T19:06:00.836895Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28, 488, 687   ',\n",
       " '0, 90, 546     ',\n",
       " '3, 80, 399     ',\n",
       " '8, 37, 881     ',\n",
       " '7, 46, 791     ',\n",
       " '5, 65, 124     ',\n",
       " '5, 61, 375     ',\n",
       " '0, 4, 82       ',\n",
       " '1, 49, 785     ',\n",
       " '25, 399, 900   ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae8d55-ae22-4dfa-aed8-dd9f015bc710",
   "metadata": {},
   "source": [
    "## Vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e26f954-9524-4931-a09f-b48698df968e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T19:06:00.916007Z",
     "iopub.status.busy": "2022-04-21T19:06:00.914721Z",
     "iopub.status.idle": "2022-04-21T19:06:01.546245Z",
     "shell.execute_reply": "2022-04-21T19:06:01.545454Z",
     "shell.execute_reply.started": "2022-04-21T19:06:00.915964Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(answers):\n",
    "    y[i] = ctable.encode(sentence, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c913fd3-f246-47c7-990b-c184fba7212b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T19:06:01.548255Z",
     "iopub.status.busy": "2022-04-21T19:06:01.547664Z",
     "iopub.status.idle": "2022-04-21T19:06:01.580511Z",
     "shell.execute_reply": "2022-04-21T19:06:01.578483Z",
     "shell.execute_reply.started": "2022-04-21T19:06:01.548214Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 15, 12)\n",
      "(45000, 15, 12)\n",
      "Validation Data:\n",
      "(5000, 15, 12)\n",
      "(5000, 15, 12)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]\n",
    "\n",
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"Validation Data:\")\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a5520e-80bb-45e1-af99-c26be423f509",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8810e0fe-81f2-410f-b7dd-a6d4a644b69a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T19:06:01.586243Z",
     "iopub.status.busy": "2022-04-21T19:06:01.585638Z",
     "iopub.status.idle": "2022-04-21T19:06:02.193906Z",
     "shell.execute_reply": "2022-04-21T19:06:02.192884Z",
     "shell.execute_reply.started": "2022-04-21T19:06:01.586130Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 21:06:01.617232: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 256)               275456    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 15, 128)           197120    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 15, 12)            1548      \n",
      "=================================================================\n",
      "Total params: 474,124\n",
      "Trainable params: 474,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model...\")\n",
    "num_layers = 1  # Try to add more LSTM layers!\n",
    "\n",
    "model = keras.Sequential()\n",
    "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
    "# Note: In a situation where your input sequences have a variable length,\n",
    "# use input_shape=(None, num_feature).\n",
    "model.add(layers.LSTM(256, input_shape=(MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input, repeatedly provide with the last output of\n",
    "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
    "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
    "model.add(layers.RepeatVector(MAXLEN))\n",
    "# The decoder RNN could be multiple layers stacked or a single layer.\n",
    "for _ in range(num_layers):\n",
    "    # By setting return_sequences to True, return not only the last output but\n",
    "    # all the outputs so far in the form of (num_samples, timesteps,\n",
    "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
    "    # the first dimension to be the timesteps.\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a0307-fd7b-41d3-b4a8-dad4a239aace",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea00cdfd-96d1-4927-9dff-2492600b00e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-21T19:06:02.195740Z",
     "iopub.status.busy": "2022-04-21T19:06:02.195114Z",
     "iopub.status.idle": "2022-04-21T19:20:50.708539Z",
     "shell.execute_reply": "2022-04-21T19:20:50.707743Z",
     "shell.execute_reply.started": "2022-04-21T19:06:02.195699Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-21 21:06:02.800815: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 55s 36ms/step - loss: 0.9009 - accuracy: 0.6629 - val_loss: 0.5878 - val_accuracy: 0.7482\n",
      "Q 68, 5, 1        T 1, 5, 68        ❌ 1, 6, 81       \n",
      "Q 603, 8, 6       T 6, 8, 603       ❌ 0, 6, 666      \n",
      "Q 9, 155, 8       T 8, 9, 155       ❌ 5, 5, 555      \n",
      "Q 195, 76, 59     T 59, 76, 195     ❌ 55, 55, 999    \n",
      "Q 0, 731, 17      T 0, 17, 731      ❌ 1, 10, 771     \n",
      "Q 769, 1, 852     T 1, 769, 852     ❌ 1, 189, 989    \n",
      "Q 96, 2, 17       T 2, 17, 96       ❌ 2, 22, 92      \n",
      "Q 69, 7, 5        T 5, 7, 69        ❌ 5, 9, 99       \n",
      "Q 9, 8, 99        T 8, 9, 99        ❌ 9, 9, 99       \n",
      "Q 0, 58, 79       T 0, 58, 79       ❌ 0, 70, 90      \n",
      "\n",
      "Iteration 2\n",
      "1407/1407 [==============================] - 49s 35ms/step - loss: 0.5554 - accuracy: 0.7605 - val_loss: 0.5459 - val_accuracy: 0.7662\n",
      "Q 0, 548, 234     T 0, 234, 548     ❌ 4, 422, 844    \n",
      "Q 731, 7, 26      T 7, 26, 731      ❌ 2, 22, 776     \n",
      "Q 3, 8, 91        T 3, 8, 91        ❌ 3, 8, 83       \n",
      "Q 99, 5, 13       T 5, 13, 99       ❌ 5, 39, 99      \n",
      "Q 56, 88, 8       T 8, 56, 88       ❌ 8, 88, 88      \n",
      "Q 6, 4, 83        T 4, 6, 83        ❌ 3, 8, 44       \n",
      "Q 23, 724, 40     T 23, 40, 724     ❌ 22, 40, 400    \n",
      "Q 9, 804, 45      T 9, 45, 804      ❌ 4, 44, 444     \n",
      "Q 82, 2, 23       T 2, 23, 82       ❌ 2, 23, 83      \n",
      "Q 267, 24, 87     T 24, 87, 267     ❌ 22, 72, 477    \n",
      "\n",
      "Iteration 3\n",
      "1407/1407 [==============================] - 51s 37ms/step - loss: 0.4309 - accuracy: 0.8204 - val_loss: 0.3252 - val_accuracy: 0.8680\n",
      "Q 86, 2, 857      T 2, 86, 857      ❌ 2, 86, 877     \n",
      "Q 707, 41, 2      T 2, 41, 707      ❌ 2, 41, 700     \n",
      "Q 4, 2, 8         T 2, 4, 8         ✅ 2, 4, 8        \n",
      "Q 21, 3, 983      T 3, 21, 983      ❌ 2, 23, 983     \n",
      "Q 4, 77, 48       T 4, 48, 77       ❌ 4, 47, 77      \n",
      "Q 7, 856, 57      T 7, 57, 856      ❌ 7, 55, 776     \n",
      "Q 427, 1, 9       T 1, 9, 427       ❌ 1, 9, 197      \n",
      "Q 96, 2, 17       T 2, 17, 96       ❌ 1, 26, 96      \n",
      "Q 6, 96, 32       T 6, 32, 96       ❌ 6, 36, 92      \n",
      "Q 13, 776, 2      T 2, 13, 776      ❌ 1, 13, 776     \n",
      "\n",
      "Iteration 4\n",
      "1407/1407 [==============================] - 50s 35ms/step - loss: 0.2773 - accuracy: 0.8871 - val_loss: 0.2180 - val_accuracy: 0.9118\n",
      "Q 8, 100, 85      T 8, 85, 100      ❌ 8, 80, 100     \n",
      "Q 36, 939, 332    T 36, 332, 939    ❌ 33, 332, 999   \n",
      "Q 513, 873, 924   T 513, 873, 924   ❌ 512, 824, 974  \n",
      "Q 45, 89, 8       T 8, 45, 89       ✅ 8, 45, 89      \n",
      "Q 852, 2, 98      T 2, 98, 852      ❌ 2, 85, 885     \n",
      "Q 7, 2, 29        T 2, 7, 29        ✅ 2, 7, 29       \n",
      "Q 99, 7, 4        T 4, 7, 99        ✅ 4, 7, 99       \n",
      "Q 7, 5, 22        T 5, 7, 22        ✅ 5, 7, 22       \n",
      "Q 9, 294, 76      T 9, 76, 294      ❌ 9, 79, 264     \n",
      "Q 7, 587, 56      T 7, 56, 587      ❌ 7, 57, 576     \n",
      "\n",
      "Iteration 5\n",
      "1407/1407 [==============================] - 57s 40ms/step - loss: 0.1962 - accuracy: 0.9218 - val_loss: 0.1592 - val_accuracy: 0.9359\n",
      "Q 7, 40, 3        T 3, 7, 40        ✅ 3, 7, 40       \n",
      "Q 335, 2, 86      T 2, 86, 335      ❌ 2, 86, 355     \n",
      "Q 39, 80, 78      T 39, 78, 80      ❌ 38, 70, 80     \n",
      "Q 15, 48, 4       T 4, 15, 48       ✅ 4, 15, 48      \n",
      "Q 394, 172, 138   T 138, 172, 394   ❌ 138, 398, 372  \n",
      "Q 68, 144, 4      T 4, 68, 144      ❌ 4, 64, 144     \n",
      "Q 7, 5, 288       T 5, 7, 288       ✅ 5, 7, 288      \n",
      "Q 29, 9, 70       T 9, 29, 70       ✅ 9, 29, 70      \n",
      "Q 68, 90, 89      T 68, 89, 90      ❌ 69, 80, 90     \n",
      "Q 760, 88, 872    T 88, 760, 872    ❌ 87, 700, 862   \n",
      "\n",
      "Iteration 6\n",
      "1407/1407 [==============================] - 50s 36ms/step - loss: 0.1615 - accuracy: 0.9391 - val_loss: 0.1180 - val_accuracy: 0.9534\n",
      "Q 25, 6, 27       T 6, 25, 27       ✅ 6, 25, 27      \n",
      "Q 7, 40, 503      T 7, 40, 503      ✅ 7, 40, 503     \n",
      "Q 3, 5, 6         T 3, 5, 6         ✅ 3, 5, 6        \n",
      "Q 4, 569, 92      T 4, 92, 569      ❌ 4, 92, 599     \n",
      "Q 36, 621, 8      T 8, 36, 621      ✅ 8, 36, 621     \n",
      "Q 60, 0, 8        T 0, 8, 60        ✅ 0, 8, 60       \n",
      "Q 554, 4, 61      T 4, 61, 554      ✅ 4, 61, 554     \n",
      "Q 7, 884, 1       T 1, 7, 884       ✅ 1, 7, 884      \n",
      "Q 9, 5, 848       T 5, 9, 848       ✅ 5, 9, 848      \n",
      "Q 7, 211, 3       T 3, 7, 211       ✅ 3, 7, 211      \n",
      "\n",
      "Iteration 7\n",
      "1407/1407 [==============================] - 48s 34ms/step - loss: 0.1129 - accuracy: 0.9573 - val_loss: 0.0937 - val_accuracy: 0.9629\n",
      "Q 93, 8, 127      T 8, 93, 127      ✅ 8, 93, 127     \n",
      "Q 877, 126, 6     T 6, 126, 877     ❌ 6, 127, 877    \n",
      "Q 9, 580, 72      T 9, 72, 580      ✅ 9, 72, 580     \n",
      "Q 82, 105, 996    T 82, 105, 996    ❌ 80, 105, 896   \n",
      "Q 7, 6, 759       T 6, 7, 759       ✅ 6, 7, 759      \n",
      "Q 64, 735, 564    T 64, 564, 735    ❌ 64, 643, 745   \n",
      "Q 9, 545, 0       T 0, 9, 545       ✅ 0, 9, 545      \n",
      "Q 34, 42, 8       T 8, 34, 42       ✅ 8, 34, 42      \n",
      "Q 37, 8, 21       T 8, 21, 37       ✅ 8, 21, 37      \n",
      "Q 273, 371, 9     T 9, 273, 371     ✅ 9, 273, 371    \n",
      "\n",
      "Iteration 8\n",
      "1407/1407 [==============================] - 47s 33ms/step - loss: 0.0759 - accuracy: 0.9711 - val_loss: 0.0826 - val_accuracy: 0.9684\n",
      "Q 43, 891, 798    T 43, 798, 891    ❌ 43, 781, 891   \n",
      "Q 60, 393, 6      T 6, 60, 393      ✅ 6, 60, 393     \n",
      "Q 60, 9, 9        T 9, 9, 60        ✅ 9, 9, 60       \n",
      "Q 0, 5, 169       T 0, 5, 169       ✅ 0, 5, 169      \n",
      "Q 3, 20, 49       T 3, 20, 49       ❌ 4, 20, 49      \n",
      "Q 694, 2, 3       T 2, 3, 694       ✅ 2, 3, 694      \n",
      "Q 19, 3, 6        T 3, 6, 19        ✅ 3, 6, 19       \n",
      "Q 586, 311, 15    T 15, 311, 586    ✅ 15, 311, 586   \n",
      "Q 4, 28, 0        T 0, 4, 28        ✅ 0, 4, 28       \n",
      "Q 72, 480, 3      T 3, 72, 480      ✅ 3, 72, 480     \n",
      "\n",
      "Iteration 9\n",
      "1407/1407 [==============================] - 44s 31ms/step - loss: 0.0876 - accuracy: 0.9690 - val_loss: 0.0651 - val_accuracy: 0.9760\n",
      "Q 374, 1, 9       T 1, 9, 374       ✅ 1, 9, 374      \n",
      "Q 89, 4, 21       T 4, 21, 89       ✅ 4, 21, 89      \n",
      "Q 9, 8, 90        T 8, 9, 90        ✅ 8, 9, 90       \n",
      "Q 1, 525, 4       T 1, 4, 525       ✅ 1, 4, 525      \n",
      "Q 496, 989, 938   T 496, 938, 989   ❌ 499, 939, 969  \n",
      "Q 64, 0, 1        T 0, 1, 64        ✅ 0, 1, 64       \n",
      "Q 3, 717, 50      T 3, 50, 717      ✅ 3, 50, 717     \n",
      "Q 0, 26, 74       T 0, 26, 74       ✅ 0, 26, 74      \n",
      "Q 14, 125, 64     T 14, 64, 125     ✅ 14, 64, 125    \n",
      "Q 1, 8, 92        T 1, 8, 92        ✅ 1, 8, 92       \n",
      "\n",
      "Iteration 10\n",
      "1407/1407 [==============================] - 41s 29ms/step - loss: 0.0460 - accuracy: 0.9837 - val_loss: 0.0519 - val_accuracy: 0.9812\n",
      "Q 24, 38, 73      T 24, 38, 73      ✅ 24, 38, 73     \n",
      "Q 8, 0, 3         T 0, 3, 8         ✅ 0, 3, 8        \n",
      "Q 270, 8, 738     T 8, 270, 738     ✅ 8, 270, 738    \n",
      "Q 59, 36, 296     T 36, 59, 296     ❌ 36, 56, 296    \n",
      "Q 106, 93, 7      T 7, 93, 106      ✅ 7, 93, 106     \n",
      "Q 580, 336, 15    T 15, 336, 580    ❌ 15, 356, 580   \n",
      "Q 64, 115, 6      T 6, 64, 115      ✅ 6, 64, 115     \n",
      "Q 2, 594, 42      T 2, 42, 594      ✅ 2, 42, 594     \n",
      "Q 36, 147, 0      T 0, 36, 147      ✅ 0, 36, 147     \n",
      "Q 612, 376, 67    T 67, 376, 612    ❌ 67, 377, 612   \n",
      "\n",
      "Iteration 11\n",
      "1407/1407 [==============================] - 43s 30ms/step - loss: 0.0394 - accuracy: 0.9862 - val_loss: 0.0474 - val_accuracy: 0.9831\n",
      "Q 2, 680, 5       T 2, 5, 680       ✅ 2, 5, 680      \n",
      "Q 69, 92, 282     T 69, 92, 282     ❌ 68, 92, 282    \n",
      "Q 224, 7, 21      T 7, 21, 224      ✅ 7, 21, 224     \n",
      "Q 4, 49, 858      T 4, 49, 858      ✅ 4, 49, 858     \n",
      "Q 90, 65, 56      T 56, 65, 90      ✅ 56, 65, 90     \n",
      "Q 6, 99, 83       T 6, 83, 99       ✅ 6, 83, 99      \n",
      "Q 99, 7, 4        T 4, 7, 99        ✅ 4, 7, 99       \n",
      "Q 9, 6, 442       T 6, 9, 442       ✅ 6, 9, 442      \n",
      "Q 26, 954, 986    T 26, 954, 986    ❌ 26, 954, 966   \n",
      "Q 0, 8, 77        T 0, 8, 77        ✅ 0, 8, 77       \n",
      "\n",
      "Iteration 12\n",
      "1407/1407 [==============================] - 46s 33ms/step - loss: 0.0677 - accuracy: 0.9790 - val_loss: 0.0446 - val_accuracy: 0.9835\n",
      "Q 63, 65, 5       T 5, 63, 65       ❌ 5, 63, 63      \n",
      "Q 55, 405, 4      T 4, 55, 405      ✅ 4, 55, 405     \n",
      "Q 7, 82, 108      T 7, 82, 108      ✅ 7, 82, 108     \n",
      "Q 36, 99, 9       T 9, 36, 99       ✅ 9, 36, 99      \n",
      "Q 269, 4, 70      T 4, 70, 269      ✅ 4, 70, 269     \n",
      "Q 6, 998, 92      T 6, 92, 998      ✅ 6, 92, 998     \n",
      "Q 31, 801, 6      T 6, 31, 801      ✅ 6, 31, 801     \n",
      "Q 947, 6, 33      T 6, 33, 947      ✅ 6, 33, 947     \n",
      "Q 21, 0, 929      T 0, 21, 929      ✅ 0, 21, 929     \n",
      "Q 7, 821, 9       T 7, 9, 821       ✅ 7, 9, 821      \n",
      "\n",
      "Iteration 13\n",
      "1407/1407 [==============================] - 45s 32ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.0378 - val_accuracy: 0.9867\n",
      "Q 139, 5, 633     T 5, 139, 633     ✅ 5, 139, 633    \n",
      "Q 6, 9, 6         T 6, 6, 9         ✅ 6, 6, 9        \n",
      "Q 13, 42, 71      T 13, 42, 71      ✅ 13, 42, 71     \n",
      "Q 9, 533, 663     T 9, 533, 663     ✅ 9, 533, 663    \n",
      "Q 136, 8, 59      T 8, 59, 136      ✅ 8, 59, 136     \n",
      "Q 52, 249, 15     T 15, 52, 249     ✅ 15, 52, 249    \n",
      "Q 693, 4, 58      T 4, 58, 693      ✅ 4, 58, 693     \n",
      "Q 28, 5, 0        T 0, 5, 28        ✅ 0, 5, 28       \n",
      "Q 8, 554, 91      T 8, 91, 554      ✅ 8, 91, 554     \n",
      "Q 3, 40, 338      T 3, 40, 338      ✅ 3, 40, 338     \n",
      "\n",
      "Iteration 14\n",
      "1407/1407 [==============================] - 44s 31ms/step - loss: 0.0418 - accuracy: 0.9871 - val_loss: 0.0376 - val_accuracy: 0.9864\n",
      "Q 279, 4, 5       T 4, 5, 279       ✅ 4, 5, 279      \n",
      "Q 944, 461, 1     T 1, 461, 944     ✅ 1, 461, 944    \n",
      "Q 91, 89, 8       T 8, 89, 91       ✅ 8, 89, 91      \n",
      "Q 2, 6, 94        T 2, 6, 94        ✅ 2, 6, 94       \n",
      "Q 511, 2, 941     T 2, 511, 941     ✅ 2, 511, 941    \n",
      "Q 99, 1, 73       T 1, 73, 99       ✅ 1, 73, 99      \n",
      "Q 851, 14, 95     T 14, 95, 851     ✅ 14, 95, 851    \n",
      "Q 646, 93, 2      T 2, 93, 646      ✅ 2, 93, 646     \n",
      "Q 750, 253, 486   T 253, 486, 750   ✅ 253, 486, 750  \n",
      "Q 46, 824, 5      T 5, 46, 824      ✅ 5, 46, 824     \n",
      "\n",
      "Iteration 15\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.0326 - val_accuracy: 0.9887\n",
      "Q 82, 791, 65     T 65, 82, 791     ✅ 65, 82, 791    \n",
      "Q 0, 645, 23      T 0, 23, 645      ✅ 0, 23, 645     \n",
      "Q 661, 2, 9       T 2, 9, 661       ✅ 2, 9, 661      \n",
      "Q 6, 4, 83        T 4, 6, 83        ✅ 4, 6, 83       \n",
      "Q 6, 8, 3         T 3, 6, 8         ✅ 3, 6, 8        \n",
      "Q 15, 810, 45     T 15, 45, 810     ✅ 15, 45, 810    \n",
      "Q 75, 78, 881     T 75, 78, 881     ✅ 75, 78, 881    \n",
      "Q 93, 797, 14     T 14, 93, 797     ✅ 14, 93, 797    \n",
      "Q 264, 3, 0       T 0, 3, 264       ✅ 0, 3, 264      \n",
      "Q 650, 620, 0     T 0, 620, 650     ✅ 0, 620, 650    \n",
      "\n",
      "Iteration 16\n",
      "1407/1407 [==============================] - 44s 31ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.0302 - val_accuracy: 0.9896\n",
      "Q 86, 7, 1        T 1, 7, 86        ✅ 1, 7, 86       \n",
      "Q 555, 2, 4       T 2, 4, 555       ✅ 2, 4, 555      \n",
      "Q 9, 3, 647       T 3, 9, 647       ✅ 3, 9, 647      \n",
      "Q 785, 6, 4       T 4, 6, 785       ✅ 4, 6, 785      \n",
      "Q 68, 73, 3       T 3, 68, 73       ✅ 3, 68, 73      \n",
      "Q 13, 218, 708    T 13, 218, 708    ✅ 13, 218, 708   \n",
      "Q 10, 6, 115      T 6, 10, 115      ✅ 6, 10, 115     \n",
      "Q 87, 6, 10       T 6, 10, 87       ✅ 6, 10, 87      \n",
      "Q 529, 19, 6      T 6, 19, 529      ✅ 6, 19, 529     \n",
      "Q 88, 48, 5       T 5, 48, 88       ✅ 5, 48, 88      \n",
      "\n",
      "Iteration 17\n",
      "1407/1407 [==============================] - 45s 32ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0246 - val_accuracy: 0.9912\n",
      "Q 616, 2, 307     T 2, 307, 616     ✅ 2, 307, 616    \n",
      "Q 746, 8, 971     T 8, 746, 971     ❌ 7, 846, 971    \n",
      "Q 477, 87, 7      T 7, 87, 477      ✅ 7, 87, 477     \n",
      "Q 39, 6, 11       T 6, 11, 39       ✅ 6, 11, 39      \n",
      "Q 4, 1, 622       T 1, 4, 622       ✅ 1, 4, 622      \n",
      "Q 61, 368, 7      T 7, 61, 368      ✅ 7, 61, 368     \n",
      "Q 4, 25, 1        T 1, 4, 25        ✅ 1, 4, 25       \n",
      "Q 21, 7, 80       T 7, 21, 80       ✅ 7, 21, 80      \n",
      "Q 631, 5, 82      T 5, 82, 631      ✅ 5, 82, 631     \n",
      "Q 906, 630, 932   T 630, 906, 932   ❌ 630, 909, 900  \n",
      "\n",
      "Iteration 18\n",
      "1407/1407 [==============================] - 44s 31ms/step - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.0684 - val_accuracy: 0.9761\n",
      "Q 27, 773, 57     T 27, 57, 773     ✅ 27, 57, 773    \n",
      "Q 3, 6, 659       T 3, 6, 659       ✅ 3, 6, 659      \n",
      "Q 65, 755, 5      T 5, 65, 755      ✅ 5, 65, 755     \n",
      "Q 888, 5, 80      T 5, 80, 888      ✅ 5, 80, 888     \n",
      "Q 38, 565, 35     T 35, 38, 565     ❌ 35, 38, 665    \n",
      "Q 3, 57, 7        T 3, 7, 57        ✅ 3, 7, 57       \n",
      "Q 190, 56, 56     T 56, 56, 190     ✅ 56, 56, 190    \n",
      "Q 9, 41, 2        T 2, 9, 41        ✅ 2, 9, 41       \n",
      "Q 153, 80, 372    T 80, 153, 372    ❌ 80, 173, 372   \n",
      "Q 68, 5, 1        T 1, 5, 68        ✅ 1, 5, 68       \n",
      "\n",
      "Iteration 19\n",
      "1407/1407 [==============================] - 38s 27ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0184 - val_accuracy: 0.9937\n",
      "Q 99, 4, 917      T 4, 99, 917      ✅ 4, 99, 917     \n",
      "Q 176, 0, 3       T 0, 3, 176       ✅ 0, 3, 176      \n",
      "Q 505, 700, 50    T 50, 505, 700    ❌ 50, 555, 700   \n",
      "Q 826, 62, 915    T 62, 826, 915    ✅ 62, 826, 915   \n",
      "Q 148, 94, 163    T 94, 148, 163    ✅ 94, 148, 163   \n",
      "Q 8, 680, 213     T 8, 213, 680     ✅ 8, 213, 680    \n",
      "Q 715, 0, 4       T 0, 4, 715       ✅ 0, 4, 715      \n",
      "Q 51, 51, 0       T 0, 51, 51       ✅ 0, 51, 51      \n",
      "Q 134, 666, 46    T 46, 134, 666    ✅ 46, 134, 666   \n",
      "Q 45, 30, 5       T 5, 30, 45       ✅ 5, 30, 45      \n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "# Train the model each generation and show predictions against the validation\n",
    "# dataset.\n",
    "for epoch in range(1, epochs):\n",
    "    print()\n",
    "    print(\"Iteration\", epoch)\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val),\n",
    "    )\n",
    "    # Select 10 samples from the validation set at random so we can visualize\n",
    "    # errors.\n",
    "    for i in range(10):\n",
    "        ind = np.random.randint(0, len(x_val))\n",
    "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
    "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
    "        q = ctable.decode(rowx[0])\n",
    "        correct = ctable.decode(rowy[0])\n",
    "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
    "        print(\"Q\", q, end=\" \")\n",
    "        print(\"T\", correct, end=\" \")\n",
    "        if correct == guess:\n",
    "            print(\"✅ \" + guess)\n",
    "        else:\n",
    "            print(\"❌ \" + guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f43ab8-2f15-4aee-a1e0-2dd3df60a576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
